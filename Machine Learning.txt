1. The value of correlation coefficient will always be:
A) between 0 and 1 B) greater than -1
C) between -1 and 1 D) between 0 and -1

Answer:C

2. Which of the following cannot be used for dimensionality reduction?
A) Lasso Regularisation B) PCA
C) Recursive feature elimination D) Ridge Regularisation

Answer:C

3. Which of the following is not a kernel in Support Vector Machines?
A) linear B) Radial Basis Function
C) hyperplane D) polynomial

Answer:C

4. Amongst the following, which one is least suitable for a dataset having non-linear decision boundaries?
A) Logistic Regression B) Naïve Bayes Classifier
C) Decision Tree Classifier D) Support Vector Classifier

Answer:A

5. In a Linear Regression problem, ‘X’ is independent variable and ‘Y’ is dependent variable, where ‘X’ represents
weight in pounds. If you convert the unit of ‘X’ to kilograms, then new coefficient of ‘X’ will be?
(1 kilogram = 2.205 pounds)
A) 2.205 × old coefficient of ‘X’ B) same as old coefficient of ‘X’
C) old coefficient of ‘X’ ÷ 2.205 D) Cannot be determined

Answer:C

6.6. As we increase the number of estimators in ADABOOST Classifier, what happens to the accuracy of the model?
A) remains same B) increases
C) decreases D) none of the above

Answer:B

7. Which of the following is not an advantage of using random forest instead of decision trees?
A) Random Forests reduce overfitting
B) Random Forests explains more variance in data then decision trees
C) Random Forests are easy to interpret
D) Random Forests provide a reliable feature importance estimate

Answer:C

8. Which of the following are correct about Principal Components?
A) Principal Components are calculated using supervised learning techniques
B) Principal Components are calculated using unsupervised learning techniques
C) Principal Components are linear combinations of Linear Variables.
D) All of the above

Answer:B and C

9. Which of the following are applications of clustering?
A) Identifying developed, developing and under-developed countries on the basis of factors like GDP, poverty
index, employment rate, population and living index
B) Identifying loan defaulters in a bank on the basis of previous years’ data of loan accounts.
C) Identifying spam or ham emails
D) Identifying different segments of disease based on BMI, blood pressure, cholesterol, blood sugar levels

Answer:C and D

10. Which of the following is(are) hyper parameters of a decision tree?
A) max_depth B) max_features
C) n_estimators D) min_samples_leaf

Answer:A and D

11. What are outliers? Explain the Inter Quartile Range(IQR) method for outlier detection.

Answer:There are various types of features present in the dataset each consists of data values either in continuous form or categorical form.Some of the values herr are far away from the most of 
	the present values in the feature.In other words, it’s data that lies outside the other values in the set.

For eg.
In this set of random numbers, 1 and 201 are outliers:
1, 99, 100, 101, 103, 109, 110, 201
“1” is an extremely low value and “201” is an extremely high value.

Interquartile range can be used to detect outliers. This is done using these steps:

Interquartile range=Q3-Q1(Third quadrant(75%) - First Quadrant(25%))

=> Calculate the interquartile range for the data.
=> Multiply the interquartile range (IQR) by 1.5 (a constant used to discern outliers).
=> Add 1.5 x (IQR) to the third quartile. Any number greater than this is a suspected outlier.
=> Subtract 1.5 x (IQR) from the first quartile. Any number less than this is a suspected outlier.

12. What is the primary difference between bagging and boosting algorithms?

Answer: Bagging technique can be an effective approach to reduce the variance of a model, to prevent over-fitting and to increase the accuracy of unstable models.
	On the other hand, Boosting enables us to implement a strong model by combining a number of weak models together.

13. What is adjusted R2 in logistic regression. How is it calculated?

Answer: R2 in logistic regression is explained as the measure of goodness of how the model fit to the training as well as testing dataset.
	R2 is a statistical measure of how close the data are to the fitted regression line.

	It is calculated as :

	Step 1: Find the correlation coefficient, r (it may be given to you in the question).
	Step 2: Square the correlation coefficient.
	Step 3: Convert the correlation coefficient to a percentage.

14. What is the difference between standardisation and normalisation?

Answer: Normalization typically means rescales the values into a range of [0,1]. Standardization typically means tranform of data to have a mean of 0 and a standard deviation of 1 (unit variance).

15. What is cross-validation? Describe one advantage and one disadvantage of using cross-validation.

Answer:Cross-validation is a technique in which we train our model using the subset of the data-set and then evaluate using the complementary subset of the data-set.There are three types of Cross validation:
	=> Validation
	=> K-Fold Cross validation
	=> Leave one out Cross Validation

	Advantages:

	=> It ‘validates’ the performance of your model on multiple ‘folds’ of your data.It can balance out the predicted features’ classes if we are dealing with an unbalanced dataset.

	Disadvantages:

	=> K-fold doesn’t really work well with sequential data (a time series of some kind). If you use it you’d be predicting past values with future value training, which is not a good way to go about things